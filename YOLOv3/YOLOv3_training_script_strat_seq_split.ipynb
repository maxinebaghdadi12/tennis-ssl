{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2366231-6a41-4883-9677-0d9c0143cfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO TIP ğŸ’¡ Replace 'model=yolov3-tiny.pt' with new 'model=yolov3-tinyu.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "Starting YOLOv3-Tiny training...\n",
      "New https://pypi.org/project/ultralytics/8.3.235 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.227 ğŸš€ Python-3.12.11 torch-2.4.0+cu121 CUDA:0 (Tesla T4, 14913MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=tennis_pose_strat_seq_split_yolov3.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov3-tiny.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov3_tiny_run_only_bbox_20_epoch, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=tennis_pose_training, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/ds/experimental/aparekh675/pose_estimation/tennis_pose_training/yolov3_tiny_run_only_bbox_20_epoch, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 1]                 \n",
      "  1                  -1  1         0  torch.nn.modules.pooling.MaxPool2d           [2, 2, 0]                     \n",
      "  2                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 1]                \n",
      "  3                  -1  1         0  torch.nn.modules.pooling.MaxPool2d           [2, 2, 0]                     \n",
      "  4                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 1]                \n",
      "  5                  -1  1         0  torch.nn.modules.pooling.MaxPool2d           [2, 2, 0]                     \n",
      "  6                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 1]               \n",
      "  7                  -1  1         0  torch.nn.modules.pooling.MaxPool2d           [2, 2, 0]                     \n",
      "  8                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 1]              \n",
      "  9                  -1  1         0  torch.nn.modules.pooling.MaxPool2d           [2, 2, 0]                     \n",
      " 10                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.padding.ZeroPad2d           [[0, 1, 0, 1]]                \n",
      " 12                  -1  1         0  torch.nn.modules.pooling.MaxPool2d           [2, 1, 0]                     \n",
      " 13                  -1  1   4720640  ultralytics.nn.modules.conv.Conv             [512, 1024, 3, 1]             \n",
      " 14                  -1  1    262656  ultralytics.nn.modules.conv.Conv             [1024, 256, 1, 1]             \n",
      " 15                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 1]              \n",
      " 16                  -2  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 17                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 18             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    885248  ultralytics.nn.modules.conv.Conv             [384, 256, 3, 1]              \n",
      " 20            [19, 15]  1   3478168  ultralytics.nn.modules.head.Detect           [4, [256, 512]]               \n",
      "YOLOv3-tiny summary: 53 layers, 12,134,184 parameters, 12,134,168 gradients, 19.0 GFLOPs\n",
      "\n",
      "Transferred 119/123 items from pretrained weights\n",
      "Freezing layer 'model.20.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 3.0Â±0.5 ms, read: 65.5Â±8.5 MB/s, size: 217.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /ds/experimental/aparekh675/pose_estimation/yolo_tennis_dataset_seq_strat_corrected_v3_only_bbox/labels/train.cache... 1600 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1600/1600 2.4Mit/s 0.0s0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 2.9Â±0.4 ms, read: 88.1Â±31.7 MB/s, size: 304.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /ds/experimental/aparekh675/pose_estimation/yolo_tennis_dataset_seq_strat_corrected_v3_only_bbox/labels/val.cache... 400 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 400/400 558.7Kit/s 0.0s\n",
      "Plotting labels to /ds/experimental/aparekh675/pose_estimation/tennis_pose_training/yolov3_tiny_run_only_bbox_20_epoch/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 19 weight(decay=0.0), 24 weight(decay=0.0005), 23 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/ds/experimental/aparekh675/pose_estimation/tennis_pose_training/yolov3_tiny_run_only_bbox_20_epoch\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/20      2.99G      1.319      1.962      1.203         26        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 100/100 6.1it/s 16.4s.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 8.4it/s 1.6s0.1s\n",
      "                   all        400        400      0.642      0.728       0.73      0.437\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/20      3.48G      1.192     0.9723      1.167         33        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 100/100 6.4it/s 15.6s.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 8.6it/s 1.5s0.1s\n",
      "                   all        400        400      0.722      0.761      0.842      0.542\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/20      3.48G      1.183     0.9009      1.169         30        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 100/100 6.4it/s 15.6s.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 8.8it/s 1.5s0.1s\n",
      "                   all        400        400      0.581      0.737      0.654      0.426\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/20      3.48G      1.143       0.84      1.154         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 100/100 6.4it/s 15.6s.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 8.6it/s 1.5s0.1s\n",
      "                   all        400        400      0.697      0.775       0.73      0.486\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/20      3.48G      1.105     0.7428      1.121         30        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 100/100 6.4it/s 15.6s.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 8.8it/s 1.5s0.1s\n",
      "                   all        400        400      0.559      0.817      0.773        0.5\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/20      3.48G      1.068     0.7013      1.106         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 100/100 6.4it/s 15.6s.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 8.8it/s 1.5s0.1s\n",
      "                   all        400        400      0.726       0.78      0.779      0.521\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/20      3.48G      1.019      0.653      1.088         38        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 100/100 6.4it/s 15.6s.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 8.8it/s 1.5s0.1s\n",
      "                   all        400        400      0.606      0.772      0.752      0.459\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/20      3.49G      1.011     0.6242      1.082         35        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 100/100 6.4it/s 15.7s.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 8.9it/s 1.5s0.1s\n",
      "                   all        400        400      0.699      0.758      0.822      0.548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/20      3.49G      1.016     0.6046      1.076         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 100/100 6.4it/s 15.6s.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 8.8it/s 1.5s0.1s\n",
      "                   all        400        400      0.627      0.788      0.775      0.499\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/20      3.49G     0.9689     0.5835      1.057         33        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 100/100 6.4it/s 15.6s.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 8.9it/s 1.5s0.1s\n",
      "                   all        400        400      0.584      0.701      0.697      0.462\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/20      3.49G     0.9342     0.5255      1.101         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 100/100 6.2it/s 16.1s.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 8.8it/s 1.5s0.1s\n",
      "                   all        400        400      0.717      0.749      0.771      0.503\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/20      3.49G     0.9111     0.5029      1.089         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 100/100 6.4it/s 15.6s.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 9.0it/s 1.4s0.1s\n",
      "                   all        400        400      0.661      0.812      0.782      0.509\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/20      3.49G     0.9003     0.4901      1.082         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 100/100 6.4it/s 15.6s.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 8.7it/s 1.5s0.1s\n",
      "                   all        400        400      0.663        0.8       0.78      0.523\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/20      3.49G     0.8753     0.4629      1.055         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 100/100 6.4it/s 15.6s.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 8.9it/s 1.5s0.1s\n",
      "                   all        400        400       0.75      0.723      0.795      0.532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/20      3.49G     0.8455     0.4395      1.038         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 100/100 6.4it/s 15.6s.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 8.8it/s 1.5s0.1s\n",
      "                   all        400        400      0.653      0.772      0.775      0.525\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/20      3.49G     0.8451     0.4368      1.044         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 100/100 6.4it/s 15.7s.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 8.8it/s 1.5s0.1s\n",
      "                   all        400        400      0.701      0.795      0.792       0.54\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/20      3.49G     0.8218     0.4226      1.033         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 100/100 6.4it/s 15.6s.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 9.0it/s 1.4s0.1s\n",
      "                   all        400        400      0.693      0.765      0.757      0.523\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/20      3.49G     0.8011     0.3983      1.007         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 100/100 6.4it/s 15.6s.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 8.9it/s 1.5s0.1s\n",
      "                   all        400        400      0.693      0.773      0.806      0.546\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/20      3.49G     0.7882     0.3903      1.018         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 100/100 6.4it/s 15.6s.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 8.9it/s 1.5s0.1s\n",
      "                   all        400        400      0.739      0.754      0.807      0.553\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/20      3.49G      0.771      0.377      1.005         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 100/100 6.4it/s 15.6s.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 8.7it/s 1.5s0.1s\n",
      "                   all        400        400      0.731      0.763      0.807      0.549\n",
      "\n",
      "20 epochs completed in 0.100 hours.\n",
      "Optimizer stripped from /ds/experimental/aparekh675/pose_estimation/tennis_pose_training/yolov3_tiny_run_only_bbox_20_epoch/weights/last.pt, 24.4MB\n",
      "Optimizer stripped from /ds/experimental/aparekh675/pose_estimation/tennis_pose_training/yolov3_tiny_run_only_bbox_20_epoch/weights/best.pt, 24.4MB\n",
      "\n",
      "Validating /ds/experimental/aparekh675/pose_estimation/tennis_pose_training/yolov3_tiny_run_only_bbox_20_epoch/weights/best.pt...\n",
      "Ultralytics 8.3.227 ğŸš€ Python-3.12.11 torch-2.4.0+cu121 CUDA:0 (Tesla T4, 14913MiB)\n",
      "YOLOv3-tiny summary (fused): 34 layers, 12,129,720 parameters, 0 gradients, 18.9 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 6.8it/s 1.9s0.1s\n",
      "                   all        400        400      0.736      0.771      0.807      0.553\n",
      "              backhand        100        100      0.819       0.51       0.69      0.336\n",
      "              forehand        100        100      0.514       0.89      0.825      0.735\n",
      "        ready_position        100        100      0.832      0.745      0.861      0.698\n",
      "                 serve        100        100      0.778       0.94      0.852      0.443\n",
      "Speed: 0.2ms preprocess, 1.4ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1m/ds/experimental/aparekh675/pose_estimation/tennis_pose_training/yolov3_tiny_run_only_bbox_20_epoch\u001b[0m\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "def main():\n",
    "    # Load the YOLOv3-Tiny model\n",
    "    # 'yolov3-tiny.pt' is the lightweight version of YOLOv3\n",
    "    model = YOLO('yolov3-tiny.pt') \n",
    "\n",
    "    print(\"Starting YOLOv3-Tiny training...\")\n",
    "    \n",
    "    # Train the model\n",
    "    results = model.train(\n",
    "        data='tennis_pose_strat_seq_split_yolov3.yaml',\n",
    "        epochs=20,\n",
    "        imgsz=640,\n",
    "        project='tennis_pose_training',\n",
    "        name='yolov3_tiny_run_only_bbox_20_epoch'\n",
    "    )\n",
    "    \n",
    "    print(\"Training finished!\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4496b32-a684-447e-b63a-95b27ca54a14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312-amd64-pytorch-ecgfounder",
   "language": "python",
   "name": "py312-amd64-pytorch-ecgfounder"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
