{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "777102d3-4455-41a3-b3fb-5c23962147ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class mapping: {'backhand': 0, 'forehand': 1}\n",
      "Gathering and splitting samples...\n",
      "Found 1000 total samples.\n",
      "Processing files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [04:05<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done!\n",
      "YOLOv8-pose dataset created at: ./yolo_tennis_dataset_seq_strat_corrected_v3_only_bbox_2_classes\n",
      "Train images: 800\n",
      "Val images: 200\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "# import random  <-- Removed random as we want deterministic sequential order\n",
    "from tqdm import tqdm\n",
    "\n",
    "def convert_to_yolo_pose(annotations_root, images_root, output_root, action_names, train_split=0.8):\n",
    "    \"\"\"\n",
    "    Converts a COCO-style pose dataset into the YOLOv8-pose format.\n",
    "    Splits data SEQUENTIALLY and STRATIFIED by class.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- 1. Create Output Directories ---\n",
    "    yolo_images_train = os.path.join(output_root, 'images', 'train')\n",
    "    yolo_images_val = os.path.join(output_root, 'images', 'val')\n",
    "    yolo_labels_train = os.path.join(output_root, 'labels', 'train')\n",
    "    yolo_labels_val = os.path.join(output_root, 'labels', 'val')\n",
    "    \n",
    "    os.makedirs(yolo_images_train, exist_ok=True)\n",
    "    os.makedirs(yolo_images_val, exist_ok=True)\n",
    "    os.makedirs(yolo_labels_train, exist_ok=True)\n",
    "    os.makedirs(yolo_labels_val, exist_ok=True)\n",
    "    \n",
    "    # --- 2. Create Class Mapping ---\n",
    "    action_to_label = {name: i for i, name in enumerate(action_names)}\n",
    "    print(f\"Class mapping: {action_to_label}\")\n",
    "    \n",
    "    all_samples = []\n",
    "\n",
    "    # --- 3. Gather Samples Per Action ---\n",
    "    print(\"Gathering and splitting samples...\")\n",
    "    \n",
    "    for action_name in action_names:\n",
    "        action_label = action_to_label[action_name]\n",
    "        json_path = os.path.join(annotations_root, f\"{action_name}.json\")\n",
    "        img_folder = os.path.join(images_root, action_name)\n",
    "        \n",
    "        if not os.path.exists(json_path):\n",
    "            print(f\"Warning: JSON file not found at {json_path}. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        with open(json_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # Map image_id -> annotations\n",
    "        image_id_to_anns = {}\n",
    "        for ann in data.get('annotations', []):\n",
    "            img_id = ann['image_id']\n",
    "            if img_id not in image_id_to_anns:\n",
    "                image_id_to_anns[img_id] = []\n",
    "            image_id_to_anns[img_id].append(ann)\n",
    "\n",
    "        # Map image_id -> image_info\n",
    "        image_id_to_info = {img['id']: img for img in data.get('images', [])}\n",
    "\n",
    "        # Temporary list to hold samples JUST for this action\n",
    "        current_action_samples = []\n",
    "\n",
    "        for img_id, annotations in image_id_to_anns.items():\n",
    "            if img_id not in image_id_to_info:\n",
    "                continue\n",
    "                \n",
    "            img_info = image_id_to_info[img_id]\n",
    "            file_name = img_info['file_name']\n",
    "            img_path = os.path.join(img_folder, file_name)\n",
    "            \n",
    "            if not os.path.exists(img_path):\n",
    "                continue\n",
    "                \n",
    "            current_action_samples.append({\n",
    "                'img_path': img_path,\n",
    "                'file_name': file_name,\n",
    "                'annotations': annotations,\n",
    "                'action_label': action_label,\n",
    "                'width': img_info['width'],\n",
    "                'height': img_info['height']\n",
    "            })\n",
    "\n",
    "        # --- KEY CHANGE: Sequential & Stratified Logic ---\n",
    "        \n",
    "        # 1. Sort by filename to ensure temporal order (B_001, B_002...)\n",
    "        current_action_samples.sort(key=lambda x: x['file_name'])\n",
    "        \n",
    "        # 2. Calculate split index for THIS specific action\n",
    "        num_train = int(len(current_action_samples) * train_split)\n",
    "        \n",
    "        # 3. Assign split and add to main list\n",
    "        for i, sample in enumerate(current_action_samples):\n",
    "            if i < num_train:\n",
    "                sample['split'] = 'train'\n",
    "            else:\n",
    "                sample['split'] = 'val'\n",
    "            \n",
    "            all_samples.append(sample)\n",
    "\n",
    "    print(f\"Found {len(all_samples)} total samples.\")\n",
    "    \n",
    "    # --- 4. Process and Write Files ---\n",
    "    print(\"Processing files...\")\n",
    "    # NOTE: random.shuffle is REMOVED to keep the order clean (though it doesn't matter for writing)\n",
    "    \n",
    "    for sample in tqdm(all_samples):\n",
    "        # Retrieve the split we assigned earlier\n",
    "        split = sample['split']\n",
    "        \n",
    "        img_path = sample['img_path']\n",
    "        img_w = sample['width']\n",
    "        img_h = sample['height']\n",
    "        \n",
    "        # Define output paths based on the split\n",
    "        yolo_img_path = os.path.join(output_root, 'images', split, sample['file_name'])\n",
    "        \n",
    "        txt_file_name = os.path.splitext(sample['file_name'])[0] + '.txt'\n",
    "        yolo_label_path = os.path.join(output_root, 'labels', split, txt_file_name)\n",
    "        \n",
    "        # Copy the image\n",
    "        shutil.copy2(img_path, yolo_img_path)\n",
    "        \n",
    "        # Create the YOLO label string\n",
    "        yolo_lines = []\n",
    "        for ann in sample['annotations']:\n",
    "            class_id = sample['action_label']\n",
    "            \n",
    "            # --- Bounding Box ---\n",
    "            bbox_xywh = ann['bbox'] # [x_min, y_min, w, h]\n",
    "            x_center = bbox_xywh[0] + bbox_xywh[2] / 2\n",
    "            y_center = bbox_xywh[1] + bbox_xywh[3] / 2\n",
    "            \n",
    "            # Normalize\n",
    "            x_center_norm = x_center / img_w\n",
    "            y_center_norm = y_center / img_h\n",
    "            w_norm = bbox_xywh[2] / img_w\n",
    "            h_norm = bbox_xywh[3] / img_h\n",
    "            \n",
    "            bbox_str = f\"{class_id} {x_center_norm:.6f} {y_center_norm:.6f} {w_norm:.6f} {h_norm:.6f}\"\n",
    "            \n",
    "            # # --- Keypoints ---\n",
    "            # keypoints = ann['keypoints']\n",
    "            # kpts_str_list = []\n",
    "            \n",
    "            # for j in range(0, len(keypoints), 3):\n",
    "            #     kpt_x = keypoints[j]\n",
    "            #     kpt_y = keypoints[j+1]\n",
    "            #     kpt_vis = keypoints[j+2]\n",
    "                \n",
    "            #     kpt_x_norm = kpt_x / img_w\n",
    "            #     kpt_y_norm = kpt_y / img_h\n",
    "                \n",
    "            #     kpts_str_list.extend([f\"{kpt_x_norm:.6f}\", f\"{kpt_y_norm:.6f}\", f\"{kpt_vis:.0f}\"])\n",
    "            \n",
    "            # kpts_str = \" \".join(kpts_str_list)\n",
    "            # yolo_lines.append(f\"{bbox_str} {kpts_str}\")\n",
    "            yolo_lines.append(bbox_str)\n",
    "            \n",
    "        with open(yolo_label_path, 'w') as f:\n",
    "            f.write(\"\\n\".join(yolo_lines))\n",
    "\n",
    "    print(\"\\nDone!\")\n",
    "    print(f\"YOLOv8-pose dataset created at: {output_root}\")\n",
    "    # Quick count check\n",
    "    train_count = len([f for f in os.listdir(yolo_images_train)])\n",
    "    val_count = len([f for f in os.listdir(yolo_images_val)])\n",
    "    print(f\"Train images: {train_count}\")\n",
    "    print(f\"Val images: {val_count}\")\n",
    "\n",
    "# --- Constants & Execution ---\n",
    "ACTIONS = ['backhand', 'forehand']\n",
    "ANNOTATIONS_DIR = './dataset/annotations'\n",
    "IMAGES_DIR = './dataset/images'\n",
    "OUTPUT_DIR = './yolo_tennis_dataset_seq_strat_corrected_v3_only_bbox_2_classes'\n",
    "\n",
    "convert_to_yolo_pose(\n",
    "    annotations_root=ANNOTATIONS_DIR,\n",
    "    images_root=IMAGES_DIR,\n",
    "    output_root=OUTPUT_DIR,\n",
    "    action_names=ACTIONS,\n",
    "    train_split=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60f08f6-36f8-4d39-89ee-c9628d6c6638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
