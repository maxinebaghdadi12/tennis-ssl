{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2366231-6a41-4883-9677-0d9c0143cfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO TIP ğŸ’¡ Replace 'model=yolov3-tiny.pt' with new 'model=yolov3-tinyu.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "Starting YOLOv3-Tiny training...\n",
      "New https://pypi.org/project/ultralytics/8.3.235 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.227 ğŸš€ Python-3.12.11 torch-2.4.0+cu121 CUDA:0 (Tesla T4, 14913MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=tennis_pose_strat_seq_split_yolov3_2_classes.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov3-tiny.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov3_tiny_run_only_bbox_20_epoch_2_classes2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=tennis_pose_training, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/ds/experimental/aparekh675/pose_estimation/tennis_pose_training/yolov3_tiny_run_only_bbox_20_epoch_2_classes2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 1]                 \n",
      "  1                  -1  1         0  torch.nn.modules.pooling.MaxPool2d           [2, 2, 0]                     \n",
      "  2                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 1]                \n",
      "  3                  -1  1         0  torch.nn.modules.pooling.MaxPool2d           [2, 2, 0]                     \n",
      "  4                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 1]                \n",
      "  5                  -1  1         0  torch.nn.modules.pooling.MaxPool2d           [2, 2, 0]                     \n",
      "  6                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 1]               \n",
      "  7                  -1  1         0  torch.nn.modules.pooling.MaxPool2d           [2, 2, 0]                     \n",
      "  8                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 1]              \n",
      "  9                  -1  1         0  torch.nn.modules.pooling.MaxPool2d           [2, 2, 0]                     \n",
      " 10                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.padding.ZeroPad2d           [[0, 1, 0, 1]]                \n",
      " 12                  -1  1         0  torch.nn.modules.pooling.MaxPool2d           [2, 1, 0]                     \n",
      " 13                  -1  1   4720640  ultralytics.nn.modules.conv.Conv             [512, 1024, 3, 1]             \n",
      " 14                  -1  1    262656  ultralytics.nn.modules.conv.Conv             [1024, 256, 1, 1]             \n",
      " 15                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 1]              \n",
      " 16                  -2  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 17                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 18             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    885248  ultralytics.nn.modules.conv.Conv             [384, 256, 3, 1]              \n",
      " 20            [19, 15]  1   3477140  ultralytics.nn.modules.head.Detect           [2, [256, 512]]               \n",
      "YOLOv3-tiny summary: 53 layers, 12,133,156 parameters, 12,133,140 gradients, 19.0 GFLOPs\n",
      "\n",
      "Transferred 119/123 items from pretrained weights\n",
      "Freezing layer 'model.20.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 3.1Â±0.5 ms, read: 57.9Â±10.4 MB/s, size: 216.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /ds/experimental/aparekh675/pose_estimation/yolo_tennis_dataset_seq_strat_corrected_v3_only_bbox_2_classes/labels/train.cache... 800 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 800/800 1.1Mit/s 0.0s0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 40.3Â±12.2 MB/s, size: 219.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /ds/experimental/aparekh675/pose_estimation/yolo_tennis_dataset_seq_strat_corrected_v3_only_bbox_2_classes/labels/val.cache... 200 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 200/200 241.0Kit/s 0.0s\n",
      "Plotting labels to /ds/experimental/aparekh675/pose_estimation/tennis_pose_training/yolov3_tiny_run_only_bbox_20_epoch_2_classes2/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 19 weight(decay=0.0), 24 weight(decay=0.0005), 23 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/ds/experimental/aparekh675/pose_estimation/tennis_pose_training/yolov3_tiny_run_only_bbox_20_epoch_2_classes2\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/20      2.99G      1.424      2.337      1.419         35        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 50/50 5.9it/s 8.5s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 8.9it/s 0.8s0.1s\n",
      "                   all        200        200      0.463      0.782      0.644      0.403\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/20      3.48G      1.214       1.02      1.246         29        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 50/50 6.5it/s 7.7s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 9.6it/s 0.7s0.1s\n",
      "                   all        200        200       0.72       0.78      0.839      0.549\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/20      3.48G      1.193     0.9297      1.228         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 50/50 6.5it/s 7.7s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 9.7it/s 0.7s0.1s\n",
      "                   all        200        200      0.674      0.785      0.792      0.501\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/20      3.48G      1.149     0.8749      1.181         29        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 50/50 6.5it/s 7.7s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 9.7it/s 0.7s0.1s\n",
      "                   all        200        200      0.617        0.8      0.865      0.543\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/20      3.48G      1.091     0.8217      1.175         28        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 50/50 6.5it/s 7.7s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 8.4it/s 0.8s0.2s\n",
      "                   all        200        200      0.596       0.81      0.747      0.501\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/20      3.48G       1.08     0.7517      1.158         33        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 50/50 6.5it/s 7.7s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 9.9it/s 0.7s0.1s\n",
      "                   all        200        200      0.484      0.752      0.574       0.32\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/20      3.48G      1.053     0.7202      1.148         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 50/50 6.5it/s 7.7s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 9.9it/s 0.7ss.1s\n",
      "                   all        200        200      0.623      0.776      0.804      0.524\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/20      3.48G      1.014      0.682      1.123         33        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 50/50 6.5it/s 7.7s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 9.9it/s 0.7s0.1s\n",
      "                   all        200        200      0.555      0.821      0.761      0.538\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/20      3.48G     0.9773     0.6494      1.096         28        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 50/50 6.5it/s 7.7s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 10.0it/s 0.7s.1s\n",
      "                   all        200        200      0.586      0.815       0.79      0.549\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/20      3.48G     0.9921     0.6271      1.117         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 50/50 6.5it/s 7.7s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 9.9it/s 0.7s0.1s\n",
      "                   all        200        200      0.622      0.811       0.79      0.543\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/20      3.48G     0.9316     0.5482      1.125         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 50/50 6.2it/s 8.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 9.8it/s 0.7s0.1s\n",
      "                   all        200        200      0.665      0.717      0.733      0.478\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/20      3.48G     0.8952     0.5232      1.104         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 50/50 6.5it/s 7.7s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 9.8it/s 0.7s0.1s\n",
      "                   all        200        200      0.603      0.792       0.79      0.507\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/20      3.48G     0.8955     0.5185      1.088         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 50/50 6.5it/s 7.7s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 10.0it/s 0.7s.1s\n",
      "                   all        200        200      0.628      0.756      0.812      0.543\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/20      3.48G     0.8464     0.5101      1.083         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 50/50 6.5it/s 7.7s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 9.5it/s 0.7s0.1s\n",
      "                   all        200        200      0.658       0.85      0.857      0.579\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/20      3.48G     0.8412     0.4809      1.088         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 50/50 6.5it/s 7.7s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 10.0it/s 0.7s.1s\n",
      "                   all        200        200      0.677      0.755      0.836      0.576\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/20      3.48G     0.8124     0.4482      1.066         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 50/50 6.5it/s 7.7s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 10.1it/s 0.7s.1s\n",
      "                   all        200        200      0.663      0.605      0.781       0.53\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/20      3.48G     0.8035     0.4528      1.048         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 50/50 6.5it/s 7.7s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 10.0it/s 0.7s.1s\n",
      "                   all        200        200      0.644       0.73      0.778      0.533\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/20      3.48G      0.779     0.4219       1.04         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 50/50 6.5it/s 7.7s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 9.9it/s 0.7s0.1s\n",
      "                   all        200        200      0.644       0.73      0.844      0.587\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/20      3.48G     0.7584     0.4124       1.04         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 50/50 6.5it/s 7.7s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 10.0it/s 0.7s.1s\n",
      "                   all        200        200      0.665      0.763      0.813      0.569\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/20      3.48G     0.7541     0.4081      1.036         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 50/50 6.5it/s 7.7s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 10.0it/s 0.7s.1s\n",
      "                   all        200        200      0.682      0.794      0.831      0.596\n",
      "\n",
      "20 epochs completed in 0.053 hours.\n",
      "Optimizer stripped from /ds/experimental/aparekh675/pose_estimation/tennis_pose_training/yolov3_tiny_run_only_bbox_20_epoch_2_classes2/weights/last.pt, 24.4MB\n",
      "Optimizer stripped from /ds/experimental/aparekh675/pose_estimation/tennis_pose_training/yolov3_tiny_run_only_bbox_20_epoch_2_classes2/weights/best.pt, 24.4MB\n",
      "\n",
      "Validating /ds/experimental/aparekh675/pose_estimation/tennis_pose_training/yolov3_tiny_run_only_bbox_20_epoch_2_classes2/weights/best.pt...\n",
      "Ultralytics 8.3.227 ğŸš€ Python-3.12.11 torch-2.4.0+cu121 CUDA:0 (Tesla T4, 14913MiB)\n",
      "YOLOv3-tiny summary (fused): 34 layers, 12,128,692 parameters, 0 gradients, 18.9 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 6.5it/s 1.1s0.2s\n",
      "                   all        200        200      0.685      0.791       0.83      0.595\n",
      "              backhand        100        100      0.803      0.613      0.761      0.392\n",
      "              forehand        100        100      0.566       0.97        0.9      0.797\n",
      "Speed: 0.2ms preprocess, 1.6ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1m/ds/experimental/aparekh675/pose_estimation/tennis_pose_training/yolov3_tiny_run_only_bbox_20_epoch_2_classes2\u001b[0m\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "def main():\n",
    "    # Load the YOLOv3-Tiny model\n",
    "    # 'yolov3-tiny.pt' is the lightweight version of YOLOv3\n",
    "    model = YOLO('yolov3-tiny.pt') \n",
    "\n",
    "    print(\"Starting YOLOv3-Tiny training...\")\n",
    "    \n",
    "    # Train the model\n",
    "    results = model.train(\n",
    "        data='tennis_pose_strat_seq_split_yolov3_2_classes.yaml',\n",
    "        epochs=20,\n",
    "        imgsz=640,\n",
    "        project='tennis_pose_training',\n",
    "        name='yolov3_tiny_run_only_bbox_20_epoch_2_classes'\n",
    "    )\n",
    "    \n",
    "    print(\"Training finished!\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4496b32-a684-447e-b63a-95b27ca54a14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312-amd64-pytorch-ecgfounder",
   "language": "python",
   "name": "py312-amd64-pytorch-ecgfounder"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
